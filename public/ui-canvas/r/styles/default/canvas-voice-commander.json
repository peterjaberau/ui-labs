{
  "name": "canvas-voice-commander",
  "type": "registry:ui",
  "dependencies": [
    "framer-motion"
  ],
  "files": [
    {
      "path": "ui-canvas/canvas-voice-commander.tsx",
      "content": "\"use client\";\n\nimport React, { useEffect, useState, useCallback, useRef } from \"react\";\nimport { motion, AnimatePresence } from \"framer-motion\";\n\nexport interface CanvasVoiceCommanderProps {\n  onCommand?: (command: string) => void;\n  className?: string;\n  customCommands?: Record<string, () => void>;\n  theme?: \"artist\" | \"minimal\" | \"futuristic\";\n  visualizerStyle?: \"bars\" | \"ink\" | \"wave\" | \"pencil\";\n  visualizerEnabled?: boolean;\n  noiseReductionEnabled?: boolean;\n  soundFeedback?: boolean;\n}\n\ninterface SpeechRecognitionEvent extends Event {\n  results: SpeechRecognitionResultList;\n  resultIndex: number;\n}\n\ninterface SpeechRecognitionResult {\n  isFinal: boolean;\n  [index: number]: SpeechRecognitionAlternative;\n}\n\ninterface SpeechRecognitionAlternative {\n  transcript: string;\n  confidence: number;\n}\n\ninterface SpeechRecognitionResultList {\n  length: number;\n  item(index: number): SpeechRecognitionResult;\n}\n\ninterface SpeechRecognitionErrorEvent extends Event {\n  error: string;\n  message?: string;\n}\n\ninterface SpeechRecognition extends EventTarget {\n  continuous: boolean;\n  interimResults: boolean;\n  lang: string;\n  start(): void;\n  stop(): void;\n  abort(): void;\n  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;\n  onend: ((event: Event) => void) | null;\n  onresult: ((event: SpeechRecognitionEvent) => void) | null;\n  onnomatch: ((event: Event) => void) | null;\n}\n\ninterface SpeechRecognitionConstructor {\n  new (): SpeechRecognition;\n}\n\ndeclare global {\n  interface Window {\n    SpeechRecognition: SpeechRecognitionConstructor;\n    webkitSpeechRecognition: SpeechRecognitionConstructor;\n  }\n}\n\nconst themes = {\n  artist: {\n    gradient: \"from-amber-500 to-rose-500 dark:from-amber-600 dark:to-rose-600\",\n    pulseColor: \"rgba(251, 146, 60, 0.5)\",\n    textColor: \"text-amber-900 dark:text-amber-100\",\n    borderColor: \"border-amber-200 dark:border-amber-800\",\n    sound: \"/sounds/brush-stroke.mp3\",\n  },\n  minimal: {\n    gradient:\n      \"from-purple-500 to-indigo-500 dark:from-purple-600 dark:to-indigo-600\",\n    pulseColor: \"rgba(99, 102, 241, 0.5)\",\n    textColor: \"text-gray-700 dark:text-gray-300\",\n    borderColor: \"border-gray-200 dark:border-gray-700\",\n    sound: \"/sounds/minimal-click.mp3\",\n  },\n  futuristic: {\n    gradient: \"from-cyan-400 to-blue-500 dark:from-cyan-500 dark:to-blue-600\",\n    pulseColor: \"rgba(34, 211, 238, 0.5)\",\n    textColor: \"text-cyan-900 dark:text-cyan-100\",\n    borderColor: \"border-cyan-200 dark:border-cyan-800\",\n    sound: \"/sounds/digital-beep.mp3\",\n  },\n};\n\nconst visualizerStyles = {\n  bars: (value: number, index: number) => ({\n    className: \"w-1 bg-gradient-to-t\",\n    style: { height: `${value * 64}px` },\n  }),\n  ink: (value: number, index: number) => ({\n    className: \"rounded-full bg-gradient-to-br\",\n    style: {\n      width: `${value * 32}px`,\n      height: `${value * 32}px`,\n      opacity: value,\n      transform: `translate(${Math.sin(index) * 20}px, ${Math.cos(index) * 20}px)`,\n    },\n  }),\n  wave: (value: number, index: number) => ({\n    className: \"w-2 bg-gradient-to-t\",\n    style: {\n      height: `${Math.sin(index + value * 10) * 32 + 32}px`,\n      opacity: value * 0.8 + 0.2,\n    },\n  }),\n  pencil: (value: number, index: number) => ({\n    className: \"w-0.5 bg-gradient-to-t\",\n    style: {\n      height: `${value * 48}px`,\n      transform: `rotate(${(index - 16) * 3}deg)`,\n    },\n  }),\n};\n\nexport default function CanvasVoiceCommander({\n  onCommand,\n  className = \"\",\n  customCommands = {},\n  theme = \"artist\",\n  visualizerStyle = \"bars\",\n  visualizerEnabled = true,\n  noiseReductionEnabled = true,\n  soundFeedback = true,\n}: CanvasVoiceCommanderProps) {\n  const [isListening, setIsListening] = useState(false);\n  const [feedback, setFeedback] = useState(\"\");\n  const [recognition, setRecognition] = useState<SpeechRecognition | null>(\n    null,\n  );\n  const [confidence, setConfidence] = useState(0);\n  const [audioData, setAudioData] = useState<number[]>(new Array(32).fill(0));\n  const [commandHistory, setCommandHistory] = useState<string[]>([]);\n  const [fallbackMode, setFallbackMode] = useState(false);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const audioBufferRef = useRef<AudioBuffer | null>(null);\n\n  const loadSound = useCallback(async (url: string) => {\n    try {\n      const response = await fetch(url);\n      const arrayBuffer = await response.arrayBuffer();\n      const audioContext = new AudioContext();\n      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n      return audioBuffer;\n    } catch (error) {\n      console.error(\"Error loading sound:\", error);\n      return null;\n    }\n  }, []);\n\n  useEffect(() => {\n    if (!soundFeedback) return;\n\n    const loadSoundEffect = async () => {\n      try {\n        const audioBuffer = await loadSound(themes[theme].sound);\n        if (audioBuffer) {\n          audioBufferRef.current = audioBuffer;\n        }\n      } catch (error) {\n        console.error(\"Error loading sound effect:\", error);\n      }\n    };\n\n    loadSoundEffect();\n  }, [theme, soundFeedback, loadSound]);\n\n  const playSound = useCallback(() => {\n    if (!soundFeedback || !audioContextRef.current || !audioBufferRef.current)\n      return;\n\n    const source = audioContextRef.current.createBufferSource();\n    source.buffer = audioBufferRef.current;\n    source.connect(audioContextRef.current.destination);\n    source.start();\n  }, [soundFeedback]);\n\n  useEffect(() => {\n    if (!visualizerEnabled || !isListening) return;\n\n    let audioContext: AudioContext;\n    let analyser: AnalyserNode;\n    let dataArray: Uint8Array;\n    let animationId: number;\n    let dynamicNoiseThreshold = 0;\n\n    const setupAudioVisualizer = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: true,\n        });\n        audioContext = new AudioContext();\n        analyser = audioContext.createAnalyser();\n        const source = audioContext.createMediaStreamSource(stream);\n\n        if (noiseReductionEnabled) {\n          const noiseFilter = audioContext.createBiquadFilter();\n          noiseFilter.type = \"highpass\";\n          noiseFilter.frequency.value = 100;\n          source.connect(noiseFilter);\n          noiseFilter.connect(analyser);\n        } else {\n          source.connect(analyser);\n        }\n\n        analyser.fftSize = 64;\n        dataArray = new Uint8Array(analyser.frequencyBinCount);\n\n        analyser.getByteFrequencyData(dataArray);\n        dynamicNoiseThreshold =\n          (Array.from(dataArray).reduce((a, b) => a + b, 0) /\n            dataArray.length) *\n          0.5;\n\n        const updateVisualizer = () => {\n          analyser.getByteFrequencyData(dataArray);\n          const processedData = Array.from(dataArray).map((val) => {\n            const normalized = val / 255;\n            return noiseReductionEnabled\n              ? Math.max(0, normalized - dynamicNoiseThreshold / 255)\n              : normalized;\n          });\n          setAudioData(processedData);\n          animationId = requestAnimationFrame(updateVisualizer);\n        };\n        updateVisualizer();\n      } catch (error) {\n        console.error(\"Error setting up audio visualizer:\", error);\n        setFallbackMode(true);\n      }\n    };\n\n    setupAudioVisualizer();\n    return () => {\n      if (audioContext) audioContext.close();\n      if (animationId) cancelAnimationFrame(animationId);\n    };\n  }, [isListening, visualizerEnabled, noiseReductionEnabled]);\n\n  useEffect(() => {\n    let recognition: SpeechRecognition | null = null;\n\n    const initializeSpeechRecognition = () => {\n      const SpeechRecognitionAPI =\n        window.SpeechRecognition || window.webkitSpeechRecognition;\n\n      if (!SpeechRecognitionAPI) {\n        console.warn(\"Speech recognition not supported\");\n        setFallbackMode(true);\n        return;\n      }\n\n      recognition = new SpeechRecognitionAPI();\n      recognition.continuous = false;\n      recognition.interimResults = true;\n      recognition.lang = \"en-US\";\n\n      recognition.onresult = (event: SpeechRecognitionEvent) => {\n        const results = event.results;\n        const currentResult = results.item(results.length - 1);\n        const firstAlternative = currentResult[0];\n        const command = firstAlternative.transcript.toLowerCase();\n        const currentConfidence = Math.round(firstAlternative.confidence * 100);\n\n        setConfidence(currentConfidence);\n        setFeedback(command);\n\n        if (currentResult.isFinal) {\n          if (soundFeedback) {\n            playSound();\n          }\n\n          if (command in customCommands) {\n            customCommands[command]();\n          }\n          onCommand?.(command);\n        }\n      };\n\n      recognition.onend = (event: Event) => {\n        setIsListening(false);\n        setConfidence(0);\n      };\n\n      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {\n        setFeedback(`Error: ${event.error}`);\n        setIsListening(false);\n        setFallbackMode(true);\n      };\n\n      setRecognition(recognition);\n    };\n\n    initializeSpeechRecognition();\n  }, [onCommand, customCommands, soundFeedback, playSound]);\n\n  const toggleListening = useCallback(() => {\n    if (fallbackMode) {\n      setFeedback(\n        \"Speech recognition not supported. Please type your commands.\",\n      );\n      return;\n    }\n\n    if (!recognition) {\n      setFeedback(\"Speech recognition not supported in this browser\");\n      return;\n    }\n\n    if (isListening) {\n      recognition.stop();\n    } else {\n      setFeedback(\"Listening...\");\n      recognition.start();\n      setIsListening(true);\n    }\n  }, [recognition, isListening, fallbackMode]);\n\n  const currentTheme = themes[theme];\n  const currentVisualizer = visualizerStyles[visualizerStyle];\n\n  return (\n    <div\n      className={`relative ${className}`}\n      role=\"application\"\n      aria-label=\"Voice Commander\"\n    >\n      <motion.div\n        className=\"relative\"\n        animate={isListening ? { scale: [1, 1.1, 1] } : {}}\n        transition={{ repeat: Infinity, duration: 2 }}\n      >\n        {isListening && (\n          <motion.div\n            className={`absolute inset-0 rounded-full bg-gradient-to-r ${currentTheme.gradient}`}\n            initial={{ scale: 1, opacity: 0.5 }}\n            animate={{ scale: 1.5, opacity: 0 }}\n            transition={{ repeat: Infinity, duration: 1.5 }}\n          />\n        )}\n\n        <motion.button\n          onClick={toggleListening}\n          className={`relative rounded-full bg-gradient-to-r ${currentTheme.gradient} dark:shadow-lg/20 \n            p-4 shadow-lg transition-all duration-300 hover:shadow-xl\n            ${isListening ? \"animate-pulse\" : \"\"}`}\n          whileHover={{ scale: 1.05 }}\n          whileTap={{ scale: 0.95 }}\n          aria-label={isListening ? \"Stop listening\" : \"Start listening\"}\n          aria-pressed={isListening}\n        >\n          <svg\n            className=\"h-6 w-6 text-white dark:text-white/90\"\n            fill=\"none\"\n            stroke=\"currentColor\"\n            viewBox=\"0 0 24 24\"\n            aria-hidden=\"true\"\n          >\n            <path\n              strokeLinecap=\"round\"\n              strokeLinejoin=\"round\"\n              strokeWidth={2}\n              d=\"M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z\"\n            />\n          </svg>\n        </motion.button>\n      </motion.div>\n\n      {visualizerEnabled && !fallbackMode && (\n        <div className=\"absolute left-1/2 top-full mt-4 -translate-x-1/2\">\n          <div className=\"flex h-16 items-end justify-center gap-0.5\">\n            {audioData.map((value, index) => {\n              const visualizerProps = currentVisualizer(value, index);\n              return (\n                <motion.div\n                  key={index}\n                  className={`${visualizerProps.className} ${currentTheme.gradient}`}\n                  style={visualizerProps.style}\n                  initial={{ opacity: 0 }}\n                  animate={{ opacity: 1 }}\n                  transition={{ duration: 0.1 }}\n                />\n              );\n            })}\n          </div>\n        </div>\n      )}\n\n      <AnimatePresence>\n        {(feedback || commandHistory.length > 0 || fallbackMode) && (\n          <motion.div\n            initial={{ opacity: 0, y: 10 }}\n            animate={{ opacity: 1, y: 0 }}\n            exit={{ opacity: 0, y: -10 }}\n            className={`absolute top-full mt-24 min-w-[300px] rounded-lg \n              bg-white/90 p-4 text-sm dark:bg-gray-900/90 ${currentTheme.textColor} \n              dark:shadow-lg/20 border border-gray-100 shadow-lg backdrop-blur-sm dark:border-gray-800`}\n            role=\"status\"\n            aria-live=\"polite\"\n          >\n            {feedback && (\n              <div className=\"mb-2 text-center font-medium\">{feedback}</div>\n            )}\n            {confidence > 0 && (\n              <div className=\"mb-2\">\n                <div className=\"h-2 w-full rounded-full bg-gray-200 dark:bg-gray-700\">\n                  <motion.div\n                    className={`h-full rounded-full bg-gradient-to-r ${currentTheme.gradient}`}\n                    initial={{ width: 0 }}\n                    animate={{ width: `${confidence}%` }}\n                  />\n                </div>\n              </div>\n            )}\n            {fallbackMode && (\n              <div className=\"mb-4\">\n                <input\n                  type=\"text\"\n                  className=\"w-full rounded-lg border border-gray-200 bg-white \n                    p-2 text-gray-900 placeholder:text-gray-500 dark:border-gray-700 dark:bg-gray-800\n                    dark:text-gray-100 dark:placeholder:text-gray-400\"\n                  placeholder=\"Type your command here...\"\n                  onKeyDown={(e) => {\n                    if (e.key === \"Enter\") {\n                      const command = e.currentTarget.value.toLowerCase();\n                      if (command) {\n                        setCommandHistory((prev) => [\n                          ...prev.slice(-4),\n                          command,\n                        ]);\n                        if (command in customCommands) {\n                          customCommands[command]();\n                        }\n                        onCommand?.(command);\n                        e.currentTarget.value = \"\";\n                      }\n                    }\n                  }}\n                  aria-label=\"Command input\"\n                />\n              </div>\n            )}\n            {commandHistory.length > 0 && (\n              <div className={`mt-3 border-t pt-2 ${currentTheme.borderColor}`}>\n                <div className=\"text-xs text-gray-500 dark:text-gray-400\">\n                  Recent Commands:\n                </div>\n                <ul\n                  className=\"mt-1 space-y-1\"\n                  role=\"log\"\n                  aria-label=\"Command history\"\n                >\n                  {commandHistory.map((cmd, i) => (\n                    <motion.li\n                      key={i}\n                      initial={{ opacity: 0, x: -10 }}\n                      animate={{ opacity: 1, x: 0 }}\n                      className=\"text-sm\"\n                    >\n                      {cmd}\n                    </motion.li>\n                  ))}\n                </ul>\n              </div>\n            )}\n          </motion.div>\n        )}\n      </AnimatePresence>\n    </div>\n  );\n}\n",
      "type": "registry:ui",
      "target": ""
    }
  ]
}